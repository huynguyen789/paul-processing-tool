{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brainstorming:\n",
    "\n",
    "Problem: \n",
    "- User has large pdf file that has factory test data. \n",
    "- PDF file is too large: 22k pages\n",
    "- Data is in a table format\n",
    "- Data inside table is messy, need parsing/cleaning\n",
    "\n",
    "General solution:\n",
    "- Use python to parse pdf file\n",
    "- Get data from pdf file, parse data in desire format, export into excel file for visualization later\n",
    "\n",
    "Specific solution, pipeline:\n",
    "- Use camelot to parse tables from pdf files\n",
    "- Detect desire table, concat them.\n",
    "- Cleaning and organizing data into a nice/correct df:\n",
    "  - Check and drop extra column (Done)\n",
    "  - Detect and concat tables\n",
    "  - Seperate first cell into extra columns\n",
    "- Export df into excel file\n",
    "\n",
    "Design note:\n",
    "- Hardcoded: check all tables, if tables 7 columns: drop first one: all tables should have 6\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working code on all files:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-19 18:03:08.624 python[48276:2293694] +[CATransaction synchronize] called within transaction\n",
      "2023-07-19 18:03:08.641 python[48276:2293694] +[CATransaction synchronize] called within transaction\n",
      "2023-07-19 18:03:12.629 python[48276:2293694] +[CATransaction synchronize] called within transaction\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for table: 6.6.2.3 Adjacent Channel Leakage Power Ratio\n",
      "Searching page 0 out of 19\n",
      "Searching page 1 out of 19\n",
      "Searching page 2 out of 19\n",
      "Found table on page 2\n",
      "Searching page 3 out of 19\n",
      "Searching page 4 out of 19\n",
      "Searching page 5 out of 19\n",
      "Searching page 6 out of 19\n",
      "Searching page 7 out of 19\n",
      "Searching page 8 out of 19\n",
      "Searching page 9 out of 19\n",
      "Searching page 10 out of 19\n",
      "Searching page 11 out of 19\n",
      "Searching page 12 out of 19\n",
      "Searching page 13 out of 19\n",
      "Searching page 14 out of 19\n",
      "Searching page 15 out of 19\n",
      "Searching page 16 out of 19\n",
      "Searching page 17 out of 19\n",
      "Searching page 18 out of 19\n",
      "Searching page 19 out of 19\n",
      "Pages to read: ['2']\n",
      "\n",
      "Processing 1/1: 2\n",
      "Estimated time remaining: 0.15 minutes\n",
      "Time taken to load table: 0.67 seconds\n",
      "\n",
      "Checking table: \n",
      "Skipping a none-desired table: \n",
      "Time taken to find target table: 0.00 seconds\n",
      "Time taken to process tables: 0.00 seconds\n",
      "No tables extracted\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import time\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import os \n",
    "import multiprocessing\n",
    "\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    # Read the PDF file using Camelot\n",
    "    print(f\"Start reading PDF file {file_path}...\")\n",
    "    tables = camelot.read_pdf(file_path, pages='all' )\n",
    "    # clean_tables(tables)\n",
    "    return tables\n",
    "\n",
    "def clean_table(table):\n",
    "    # print(f\"\\nStart cleaning table...\")\n",
    "    # Check if the table has more than 1 column\n",
    "    if table.shape[1] > 1:\n",
    "        # print(f'Table has {table.shape[1]} columns. Cleaning up...')\n",
    "        # # Drop the first column\n",
    "        table = table.drop(columns=0)\n",
    "        # Reset the column names\n",
    "        table.columns = range(table.shape[1])\n",
    "        # print(f'Table now has {table.shape[1]} columns.')\n",
    "    return table\n",
    "\n",
    "# Find target_table location in the PDF file: \n",
    "# return a list of page numbers\n",
    "def find_table_location(pdf_file, target_table):\n",
    "    print(f\"Searching for table: {target_table}\")\n",
    "    \n",
    "    reader = PdfReader(pdf_file)\n",
    "\n",
    "    pages_with_table = []\n",
    "\n",
    "    for page_num in range(len(reader.pages)):\n",
    "\n",
    "        print(f\"Searching page {page_num} out of {len(reader.pages)}\")\n",
    "        \n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        if target_table in text:\n",
    "            print(f\"Found table on page {page_num}\")\n",
    "            pages_with_table.append(page_num)\n",
    "\n",
    "            # Check for multi-page\n",
    "            if page_num < len(reader.pages)-2:\n",
    "\n",
    "                # Get page_num+2 \n",
    "                next_page = reader.pages[page_num+2]  \n",
    "                next_text = next_page.extract_text()\n",
    "\n",
    "                if re.search(r'\\d+\\.\\d+\\.\\d+', next_text):\n",
    "                    pages_with_table.append(page_num + 2)\n",
    "\n",
    "            # Add extra page    \n",
    "            if pages_with_table:\n",
    "                pages_with_table.append(pages_with_table[-1] + 2)\n",
    "\n",
    "    # print(f\"Table pages found: {pages_with_table}\")\n",
    "                \n",
    "    return pages_with_table\n",
    "\n",
    "def convert_to_ranges(numbers):\n",
    "    \"\"\"\n",
    "    Convert a list of numbers into a list of ranges.\n",
    "    \"\"\"\n",
    "    ranges = []\n",
    "    \n",
    "    for i in range(0, len(numbers), 2):\n",
    "        \n",
    "        if i < len(numbers) - 1:\n",
    "            ranges.append(f\"{numbers[i]}-{numbers[i+1]}\")\n",
    "        else:\n",
    "            ranges.append(str(numbers[i]))\n",
    "\n",
    "    return ranges\n",
    "\n",
    "def display_tables(tables):\n",
    "    # Set the max column width to a high number (e.g., 1000) to display long contents\n",
    "    pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "    # Display all tables\n",
    "    print(f\"Displaying {len(tables)} tables:\")\n",
    "    for i, table in enumerate(tables):\n",
    "        table_number = i + 1\n",
    "        print(f\"\\nTable {table_number}\")\n",
    "        display(table.df)\n",
    "\n",
    "def display_processed_tables(tables):\n",
    "    # Set the max column width to a high number (e.g., 1000) to display long contents\n",
    "    pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "    # Display all processed tables\n",
    "    print(f\"\\nDisplaying {len(tables)} tables:\")\n",
    "    for i, df in enumerate(tables):\n",
    "        print(f\"Table {i + 1}\")\n",
    "        display(df)\n",
    "\n",
    "def extract_band(tables):\n",
    "    print(f\"Extracting Band info...\")\n",
    "    for table in tables:\n",
    "        line2 = table.iloc[0,0]\n",
    "        if 'Band' in line2:\n",
    "            band_info = line2.split(' ')\n",
    "            for word in band_info:\n",
    "                if word.startswith('Band'):\n",
    "                    band_num = word[4:]  # Extract everything after \"Band\"\n",
    "                    table.insert(1, 'Band', band_num)\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No 'Band' keyword in line: {line2}\")\n",
    "    return tables\n",
    "\n",
    "def extract_info(tables):\n",
    "    print(f\"Extracting Testname, ULCH, BW, MOD, RD info...\")\n",
    "    for i, table in enumerate(tables):\n",
    "        # Define patterns\n",
    "        testname_pattern = r\"(.*):@\"\n",
    "        ulch_pattern = r\"ULCH: (\\d+),\"\n",
    "        bw_pattern = r\"BW: ([\\d\\.]+ MHz)\"\n",
    "        mod_pattern = r\"UL_MOD_RB: ([^,]+),\"\n",
    "        rd_pattern = r\"UL_MOD_RB: [^,]+, (.*)\"\n",
    "\n",
    "        # Extract info\n",
    "        table['Testname'] = table.iloc[:,0].str.extract(testname_pattern)\n",
    "        table['ULCH'] = table.iloc[:,0].str.extract(ulch_pattern)\n",
    "        table['BW'] = table.iloc[:,0].str.extract(bw_pattern)\n",
    "        table['MOD'] = table.iloc[:,0].str.extract(mod_pattern)\n",
    "        table['RD'] = table.iloc[:,0].str.extract(rd_pattern)\n",
    "\n",
    "        # Drop the first column\n",
    "        table.drop(table.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        # Reorganize the columns\n",
    "        print(f\"Reorganizing columns...\")\n",
    "        new_column_order = ['Testname', 'Band', 'ULCH', 'BW', 'MOD', 'RD', 'Limit Low', 'Limit High', 'Measured', 'Unit', 'Status']\n",
    "        table = table.reindex(columns=new_column_order)\n",
    "\n",
    "        # Replace the table in the list with the cleaned and reorganized table\n",
    "        tables[i] = table\n",
    "        \n",
    "    return tables    \n",
    "\n",
    "def find_target_table(tables, desired_name):\n",
    "    \n",
    "    current_table = None\n",
    "    desired_tables = []\n",
    "    \n",
    "    #Run through table_list\n",
    "    for table in tables:\n",
    "        first_cell = table.df.iloc[0,0].split('\\n')[0]\n",
    "\n",
    "        #If the cell in first row, first column has the desire format \"6.x.x.x\" AND the desire_name: Start a new table\n",
    "        if first_cell.startswith(\"6.\") and desired_name in first_cell:\n",
    "            # Found start of new desired table\n",
    "            \n",
    "            if current_table is None:\n",
    "                current_table = table\n",
    "            current_table = table.df.copy()\n",
    "            # print(f\"Found start of new desired table:\")   \n",
    "            # display(current_table)\n",
    "        elif first_cell.startswith(\"6.\") and desired_name not in first_cell: \n",
    "            #else: return the current table, and reset the current_table to None\n",
    "            # print(f\"\\nSkipping a none-desired table: {first_cell}\")\n",
    "            if current_table is not None:\n",
    "                # Save the current table\n",
    "                desired_tables.append(current_table)\n",
    "                #Reset, mark end of the desired table\n",
    "                current_table = None\n",
    "        \n",
    "        #if the table doesnt match the desire_format AND there is a current_table: concat this table into the current table:         \n",
    "        elif current_table is not None:\n",
    "            # Continuation of previous desired table\n",
    "            # print(f\"Found continuation of previous desired table: {table.df.iloc[0,0]}\")\n",
    "            # print(f\"Found continuous table, before cleaning:\")   \n",
    "            # display(table.df)\n",
    "            #Clean table before concat:\n",
    "            table.df = clean_table(table.df)\n",
    "            # print(f\"Continuous table after cleaning:\")   \n",
    "            # display(table.df)\n",
    "            current_table = pd.concat([current_table, table.df])\n",
    "\n",
    "            # print(f\"Table after concat:\")\n",
    "            # display(current_table)\n",
    "        \n",
    "            \n",
    "    return desired_tables\n",
    "\n",
    "def process_tables(tables):  \n",
    "\n",
    "    processed_tables = []\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        # print(f\"\\nProcessing table {i+1}...\")\n",
    "        # print(f\"Table before processing:\")\n",
    "        # display(table)\n",
    "\n",
    "    \n",
    "        # Split the first cell of the first row and use it as column headers\n",
    "        first_row = table.iloc[0, 0]\n",
    "        headers = first_row.split('\\n')  \n",
    "        # print(f\"First row: {first_row}\")\n",
    "        # print(f\"Headers: {headers}\")\n",
    "        # headers.append(\"MissingHeader\")\n",
    "        table.columns = headers\n",
    "        \n",
    "        # Extract the table name from the first row\n",
    "        table_name = table.iloc[0, 0].split('\\n')[0]\n",
    "\n",
    "        \n",
    "        # Extract Band info from column 2\n",
    "        # print(f\"Extracting Band info...\")\n",
    "        line2 = table.iloc[1,0]\n",
    "        # print(f\"line2: {line2}\")\n",
    "        if 'Band' in line2:\n",
    "            band_info = line2.split(' ')\n",
    "            for word in band_info:\n",
    "                if word.startswith('Band'):\n",
    "                    band_num = word[4:]  # Extract everything after \"Band\"\n",
    "                    table.insert(1, 'Band', band_num)\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No 'Band' keyword in line: {line2}\")\n",
    "         \n",
    "\n",
    "        # print(\"Table after header:\")\n",
    "        # display(table)\n",
    "          \n",
    "        # # Check if the expected columns are in the table\n",
    "        # if 'Unit' not in table.columns:\n",
    "        #     print(f\"Table {i+1} doesn't have the expected structure. Skipping...\")\n",
    "        #     continue\n",
    "  \n",
    "        # Extract Testname, ULCH, BW, MOD, RD info\n",
    "        # print(f\"Extracting Testname, ULCH, BW, MOD, RD info...\")\n",
    "        # Define patterns\n",
    "        testname_pattern = r\"(.*):@\"\n",
    "        ulch_pattern = r\"ULCH: (\\d+),\"\n",
    "        bw_pattern = r\"BW: ([\\d\\.]+ MHz)\"\n",
    "        mod_pattern = r\"UL_MOD_RB: ([^,]+),\"\n",
    "        rd_pattern = r\"UL_MOD_RB: [^,]+, (.*)\"\n",
    "\n",
    "        # Extract info\n",
    "        table['Testname'] = table.iloc[:,0].str.extract(testname_pattern)\n",
    "        table['ULCH'] = table.iloc[:,0].str.extract(ulch_pattern)\n",
    "        table['BW'] = table.iloc[:,0].str.extract(bw_pattern)\n",
    "        table['MOD'] = table.iloc[:,0].str.extract(mod_pattern)\n",
    "        table['RD'] = table.iloc[:,0].str.extract(rd_pattern)\n",
    "        \n",
    "        # print(f\"Table before split Unit column:\")\n",
    "        # display(table)\n",
    "   \n",
    "        # Split 'Measured' and 'Unit' columns \n",
    "        # Create a temporary DataFrame for the split results\n",
    "        split_df = table['Unit'].str.split(expand=True)\n",
    "\n",
    "        # Assign the split results to 'Measured' and 'Unit' only where there are values\n",
    "        table.loc[split_df[0].notna(), 'Measured'] = split_df.loc[split_df[0].notna(), 0]\n",
    "        table.loc[split_df[1].notna(), 'Unit'] = split_df.loc[split_df[1].notna(), 1]\n",
    "\n",
    "        # Drop the first column\n",
    "        table.drop(table.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        # Create a new column filled with the table name\n",
    "        table.insert(0, 'Table Name', table_name)\n",
    "        table = table.iloc[1:]\n",
    "        \n",
    "        # Reorganize the columns\n",
    "        # print(f\"Reorganizing columns...\")\n",
    "        new_column_order = ['Table Name', 'Testname', 'Band', 'ULCH', 'BW', 'MOD', 'RD', 'Limit Low', 'Limit High', 'Measured', 'Unit', 'Status']\n",
    "        table = table.reindex(columns=new_column_order)\n",
    "\n",
    "        # Drop rows with NaN values in Testname and Band columns\n",
    "        table = table.dropna(subset=['Testname'], how='all')\n",
    "\n",
    "\n",
    "        # Reset the index\n",
    "        table.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        #Append processed table to processed_tables:\n",
    "        processed_tables.append(table)\n",
    "        \n",
    "        \n",
    "    return processed_tables\n",
    "\n",
    "\n",
    "#UI TKINTER:\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "# Add a GUI file picker\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "file_path = filedialog.askopenfilename()\n",
    "\n",
    "pdf_file = file_path\n",
    "# Extract name without extension\n",
    "file_name = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "\n",
    "# \"LTE_3GPP_v15_r8_FDD_FORD_All_TEMPS_TCU2_5_ROW_012023_5GSIM_AT_2023-06-28_16-27-57_188.pdf\"\n",
    "#  \"25C_DATA_Extract(1temperatureOnly).pdf\"\n",
    "# \"300_pages_extract.pdf\"\n",
    "\n",
    "target_table = \"6.2.2 Maximum Output Power\" \n",
    "# pdf_file = \"300_pages_extract.pdf\"\n",
    "# Extract name without extension\n",
    "file_name = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "\n",
    "\n",
    "# Find target table pages\n",
    "pages = find_table_location(pdf_file, target_table)\n",
    "\n",
    "# Format page numbers for camelot\n",
    "page_ranges = convert_to_ranges(pages)\n",
    "print(f\"Pages to read: {page_ranges}\")\n",
    "\n",
    "\n",
    "clean_tables = []\n",
    "total_ranges = len(page_ranges)\n",
    "\n",
    "\n",
    "for i, page_range in enumerate(page_ranges):\n",
    "    \n",
    "    print(f\"\\nProcessing page range {i+1}/{total_ranges}...\")\n",
    "    # Calculate the estimate time remaining based on the progress so far\n",
    "    progress = i / total_ranges\n",
    "    time_remaining = (total_ranges - i) * 9 / 60\n",
    "    print(f\"Estimated time remaining: {time_remaining:.2f} minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Read all tables from pdf\n",
    "    long_tables = camelot.read_pdf(pdf_file, pages=page_range, backend=\"poppler\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to load table: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    desire_tables = find_target_table(long_tables, \"6.2.2 Maximum Output Power\")\n",
    "    # display_processed_tables(desire_tables)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to find target table: {end_time - start_time:.2f} seconds\")\n",
    "   \n",
    "    \n",
    "    start_time = time.time()\n",
    "    processed_table = process_tables(desire_tables)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to process tables: {end_time - start_time:.2f} seconds\")\n",
    "    display_processed_tables(processed_table)\n",
    "    \n",
    "    \n",
    "    #append to clean_tables:\n",
    "    clean_tables.extend(processed_table)\n",
    "\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "all_tables = pd.concat(clean_tables, ignore_index=True)\n",
    "display(all_tables.head(10)) # Display the first few rows of the resulting dataframe\n",
    "\n",
    "# Save to Excel using file name\n",
    "excel_file = f\"final_{file_name}.xlsx\" \n",
    "all_tables.to_excel(excel_file, index=False)\n",
    "\n",
    "#Auto open folder:\n",
    "import subprocess\n",
    "import platform\n",
    "folder_path = os.path.dirname(excel_file)\n",
    "\n",
    "if platform.system() == 'Windows':\n",
    "    os.startfile(folder_path)\n",
    "\n",
    "elif platform.system() == 'Darwin': \n",
    "    subprocess.Popen(['open', folder_path])\n",
    "\n",
    "else:\n",
    "    subprocess.Popen(['xdg-open', folder_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"22kPDF.txt\", \"r\") as file:\n",
    "    page_ranges = file.read().splitlines()\n",
    "page_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_tables = []\n",
    "total_ranges = len(page_ranges)\n",
    "for i, page_range in enumerate(page_ranges):\n",
    "    \n",
    "    print(f\"Processing page range {i+1}/{total_ranges}...\")\n",
    "    # Calculate the estimate time remaining based on the progress so far\n",
    "    progress = i / total_ranges\n",
    "    time_remaining = (total_ranges - i) * 9 / 60\n",
    "    print(f\"Estimated time remaining: {time_remaining:.2f} minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Read all tables from pdf\n",
    "    long_tables = camelot.read_pdf(long_file, pages=page_range)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to load table: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    desire_tables = find_target_table(long_tables, \"6.2.2 Maximum Output Power\")\n",
    "    # display_processed_tables(desire_tables)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to find target table: {end_time - start_time:.2f} seconds\")\n",
    "   \n",
    "    \n",
    "    start_time = time.time()\n",
    "    processed_table = process_tables(desire_tables)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to process tables: {end_time - start_time:.2f} seconds\")\n",
    "    display_processed_tables(processed_table)\n",
    "    \n",
    "    \n",
    "    #append to clean_tables:\n",
    "    clean_tables.extend(processed_table)\n",
    "    \n",
    "\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "all_tables = pd.concat(clean_tables, ignore_index=True)\n",
    "display(all_tables.head(10)) # Display the first few rows of the resulting dataframe\n",
    "\n",
    "# Export the dataframe to an Excel file\n",
    "all_tables.to_excel(\"all_tables.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working Extract 6.6.2.3 Adjacent Channel Leakage Power Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for table: 6.6.2.3 Adjacent Channel Leakage Power Ratio\n",
      "Searching page 0 out of 19\n",
      "Searching page 1 out of 19\n",
      "Searching page 2 out of 19\n",
      "Start new target table on page 2\n",
      "Searching page 3 out of 19\n",
      "Searching page 4 out of 19\n",
      "Searching page 5 out of 19\n",
      "Searching page 6 out of 19\n",
      "Searching page 7 out of 19\n",
      "Searching page 8 out of 19\n",
      "Searching page 9 out of 19\n",
      "Searching page 10 out of 19\n",
      "Searching page 11 out of 19\n",
      "Searching page 12 out of 19\n",
      "Searching page 13 out of 19\n",
      "Searching page 14 out of 19\n",
      "Searching page 15 out of 19\n",
      "Searching page 16 out of 19\n",
      "Searching page 17 out of 19\n",
      "Searching page 18 out of 19\n",
      "Searching page 19 out of 19\n",
      "End of continuous table on page 19\n",
      "Pages to read: ['2-19']\n",
      "\n",
      "Processing 1/1: 2-19\n",
      "Estimated time remaining: 0.15 minutes\n",
      "Time taken to load table: 11.74 seconds\n",
      "\n",
      "Checking table: \n",
      "Skipping a none-desired table: \n",
      "\n",
      "Checking table: \n",
      "Skipping a none-desired table: \n",
      "\n",
      "Checking table: 6.6.2.2 Additional Spectrum Emission Mask \n",
      "Skipping a none-desired table: 6.6.2.2 Additional Spectrum Emission Mask \n",
      "\n",
      "Checking table: 6.6.2.3 Adjacent Channel Leakage Power Ratio \n",
      "Found start of new desired table:6.6.2.3 Adjacent Channel Leakage Power Ratio \n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: QPSK, 25 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UTRA ACLR2 (+10MHz):@ULCH: 18025, BW: 5.0 MHz ;\n",
      "UL_MOD_RB: Q16, 25 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: QPSK, 8 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UTRA ACLR2 (-10MHz):@ULCH: 18300, BW: 5.0 MHz ;\n",
      "UL_MOD_RB: Q16, 8 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: QPSK, 8 (RB_Pos:HIGH)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UTRA ACLR1 (+5MHz):@ULCH: 18575, BW: 5.0 MHz ;\n",
      "UL_MOD_RB: Q16, 8 (RB_Pos:HIGH)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: QPSK, 12 (RB_Pos:HIGH)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UTRA ACLR1 (-7.5MHz):@ULCH: 18300, BW: 10 MHz ;\n",
      "UL_MOD_RB: QPSK, 50 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: Q16, 50 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: E-UTRA ACLR (+10MHz):@ULCH: 18550, BW: 10 MHz ;\n",
      "UL_MOD_RB: QPSK, 12 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: Q16, 12 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UTRA ACLR1 (+12.5MHz):@ULCH: 18100, BW: 20 MHz ;\n",
      "UL_MOD_RB: QPSK, 18 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: Q16, 18 (RB_Pos:LOW)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UTRA ACLR1 (-12.5MHz):@ULCH: 18300, BW: 20 MHz ;\n",
      "UL_MOD_RB: QPSK, 18 (RB_Pos:HIGH)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: UL_MOD_RB: Q16, 18 (RB_Pos:HIGH)\n",
      "\n",
      "Checking table: \n",
      "Found continuation of previous desired table: E-UTRA ACLR (+20MHz):@ULCH: 18500, BW: 20 MHz ;\n",
      "UL_MOD_RB: Q16, 100 (RB_Pos:LOW)\n",
      "Saving table:                                                                                                0  \\\n",
      "0   6.6.2.3 Adjacent Channel Leakage Power Ratio \\nLimit Low\\nLimit High\\nMeasured\\nUnit\\nStatus   \n",
      "1                                           6.6.2.3 Adjacent Channel Leakage Power Ratio @ Band1   \n",
      "2              E-UTRA ACLR (-5MHz):@ULCH: 18025, BW: 5.0 MHz ;\\nUL_MOD_RB: QPSK, 25 (RB_Pos:LOW)   \n",
      "3              E-UTRA ACLR (+5MHz):@ULCH: 18025, BW: 5.0 MHz ;\\nUL_MOD_RB: QPSK, 25 (RB_Pos:LOW)   \n",
      "4                                                 UTRA ACLR1 (-5MHz):@ULCH: 18025, BW: 5.0 MHz ;   \n",
      "..                                                                                           ...   \n",
      "12             E-UTRA ACLR (+20MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
      "13            UTRA ACLR1 (-12.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
      "14            UTRA ACLR1 (+12.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
      "15            UTRA ACLR2 (-17.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
      "16            UTRA ACLR2 (+17.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
      "\n",
      "        1    2 3          4       5  \n",
      "0                                    \n",
      "1                                    \n",
      "2   29.20  ---     45.38 dB  Passed  \n",
      "3   29.20  ---     44.93 dB  Passed  \n",
      "4   32.20  ---     46.24 dB  Passed  \n",
      "..    ...  ... ..       ...     ...  \n",
      "12  29.20  ---     43.54 dB  Passed  \n",
      "13  32.20  ---     53.70 dB  Passed  \n",
      "14  32.20  ---     45.73 dB  Passed  \n",
      "15  35.20  ---     53.37 dB  Passed  \n",
      "16  35.20  ---     51.01 dB  Passed  \n",
      "\n",
      "[345 rows x 6 columns]\n",
      "\n",
      "Displaying 1 tables:\n",
      "Table 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio \\nLimit Low\\nLimit High\\nMeasured\\nUnit\\nStatus</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio @ Band1</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E-UTRA ACLR (-5MHz):@ULCH: 18025, BW: 5.0 MHz ;\\nUL_MOD_RB: QPSK, 25 (RB_Pos:LOW)</td>\n",
       "      <td>29.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>45.38 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E-UTRA ACLR (+5MHz):@ULCH: 18025, BW: 5.0 MHz ;\\nUL_MOD_RB: QPSK, 25 (RB_Pos:LOW)</td>\n",
       "      <td>29.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>44.93 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UTRA ACLR1 (-5MHz):@ULCH: 18025, BW: 5.0 MHz ;</td>\n",
       "      <td>32.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>46.24 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E-UTRA ACLR (+20MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)</td>\n",
       "      <td>29.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>43.54 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UTRA ACLR1 (-12.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)</td>\n",
       "      <td>32.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>53.70 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UTRA ACLR1 (+12.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)</td>\n",
       "      <td>32.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>45.73 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UTRA ACLR2 (-17.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)</td>\n",
       "      <td>35.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>53.37 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UTRA ACLR2 (+17.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)</td>\n",
       "      <td>35.20</td>\n",
       "      <td>---</td>\n",
       "      <td></td>\n",
       "      <td>51.01 dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>345 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                               0  \\\n",
       "0   6.6.2.3 Adjacent Channel Leakage Power Ratio \\nLimit Low\\nLimit High\\nMeasured\\nUnit\\nStatus   \n",
       "1                                           6.6.2.3 Adjacent Channel Leakage Power Ratio @ Band1   \n",
       "2              E-UTRA ACLR (-5MHz):@ULCH: 18025, BW: 5.0 MHz ;\\nUL_MOD_RB: QPSK, 25 (RB_Pos:LOW)   \n",
       "3              E-UTRA ACLR (+5MHz):@ULCH: 18025, BW: 5.0 MHz ;\\nUL_MOD_RB: QPSK, 25 (RB_Pos:LOW)   \n",
       "4                                                 UTRA ACLR1 (-5MHz):@ULCH: 18025, BW: 5.0 MHz ;   \n",
       "..                                                                                           ...   \n",
       "12             E-UTRA ACLR (+20MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
       "13            UTRA ACLR1 (-12.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
       "14            UTRA ACLR1 (+12.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
       "15            UTRA ACLR2 (-17.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
       "16            UTRA ACLR2 (+17.5MHz):@ULCH: 18500, BW: 20 MHz ;\\nUL_MOD_RB: Q16, 18 (RB_Pos:HIGH)   \n",
       "\n",
       "        1    2 3          4       5  \n",
       "0                                    \n",
       "1                                    \n",
       "2   29.20  ---     45.38 dB  Passed  \n",
       "3   29.20  ---     44.93 dB  Passed  \n",
       "4   32.20  ---     46.24 dB  Passed  \n",
       "..    ...  ... ..       ...     ...  \n",
       "12  29.20  ---     43.54 dB  Passed  \n",
       "13  32.20  ---     53.70 dB  Passed  \n",
       "14  32.20  ---     45.73 dB  Passed  \n",
       "15  35.20  ---     53.37 dB  Passed  \n",
       "16  35.20  ---     51.01 dB  Passed  \n",
       "\n",
       "[345 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken to find target table: 0.01 seconds\n",
      "Time taken to process tables: 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table Name</th>\n",
       "      <th>Testname</th>\n",
       "      <th>Band</th>\n",
       "      <th>ULCH</th>\n",
       "      <th>BW</th>\n",
       "      <th>MOD</th>\n",
       "      <th>RD</th>\n",
       "      <th>Limit Low</th>\n",
       "      <th>Limit High</th>\n",
       "      <th>Measured</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>E-UTRA ACLR (-5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>25 (RB_Pos:LOW)</td>\n",
       "      <td>29.20</td>\n",
       "      <td>---</td>\n",
       "      <td>45.38</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>E-UTRA ACLR (+5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>25 (RB_Pos:LOW)</td>\n",
       "      <td>29.20</td>\n",
       "      <td>---</td>\n",
       "      <td>44.93</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>UTRA ACLR1 (-5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.20</td>\n",
       "      <td>---</td>\n",
       "      <td>46.24</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>UTRA ACLR1 (+5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>25 (RB_Pos:LOW)</td>\n",
       "      <td>32.20</td>\n",
       "      <td>---</td>\n",
       "      <td>45.69</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>UTRA ACLR2 (-10MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>25 (RB_Pos:LOW)</td>\n",
       "      <td>35.20</td>\n",
       "      <td>---</td>\n",
       "      <td>49.63</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>UTRA ACLR2 (+10MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>25 (RB_Pos:LOW)</td>\n",
       "      <td>35.20</td>\n",
       "      <td>---</td>\n",
       "      <td>47.69</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>E-UTRA ACLR (-5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>8 (RB_Pos:LOW)</td>\n",
       "      <td>29.20</td>\n",
       "      <td>---</td>\n",
       "      <td>46.10</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>E-UTRA ACLR (+5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>8 (RB_Pos:LOW)</td>\n",
       "      <td>29.20</td>\n",
       "      <td>---</td>\n",
       "      <td>51.03</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>UTRA ACLR1 (-5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>8 (RB_Pos:LOW)</td>\n",
       "      <td>32.20</td>\n",
       "      <td>---</td>\n",
       "      <td>47.33</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6.6.2.3 Adjacent Channel Leakage Power Ratio</td>\n",
       "      <td>UTRA ACLR1 (+5MHz)</td>\n",
       "      <td>1</td>\n",
       "      <td>18025</td>\n",
       "      <td>5.0 MHz</td>\n",
       "      <td>QPSK</td>\n",
       "      <td>8 (RB_Pos:LOW)</td>\n",
       "      <td>32.20</td>\n",
       "      <td>---</td>\n",
       "      <td>52.07</td>\n",
       "      <td>dB</td>\n",
       "      <td>Passed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Table Name             Testname Band  \\\n",
       "0  6.6.2.3 Adjacent Channel Leakage Power Ratio   E-UTRA ACLR (-5MHz)    1   \n",
       "1  6.6.2.3 Adjacent Channel Leakage Power Ratio   E-UTRA ACLR (+5MHz)    1   \n",
       "2  6.6.2.3 Adjacent Channel Leakage Power Ratio    UTRA ACLR1 (-5MHz)    1   \n",
       "3  6.6.2.3 Adjacent Channel Leakage Power Ratio    UTRA ACLR1 (+5MHz)    1   \n",
       "4  6.6.2.3 Adjacent Channel Leakage Power Ratio   UTRA ACLR2 (-10MHz)    1   \n",
       "5  6.6.2.3 Adjacent Channel Leakage Power Ratio   UTRA ACLR2 (+10MHz)    1   \n",
       "6  6.6.2.3 Adjacent Channel Leakage Power Ratio   E-UTRA ACLR (-5MHz)    1   \n",
       "7  6.6.2.3 Adjacent Channel Leakage Power Ratio   E-UTRA ACLR (+5MHz)    1   \n",
       "8  6.6.2.3 Adjacent Channel Leakage Power Ratio    UTRA ACLR1 (-5MHz)    1   \n",
       "9  6.6.2.3 Adjacent Channel Leakage Power Ratio    UTRA ACLR1 (+5MHz)    1   \n",
       "\n",
       "    ULCH       BW   MOD               RD Limit Low Limit High Measured Unit  \\\n",
       "0  18025  5.0 MHz  QPSK  25 (RB_Pos:LOW)     29.20        ---    45.38   dB   \n",
       "1  18025  5.0 MHz  QPSK  25 (RB_Pos:LOW)     29.20        ---    44.93   dB   \n",
       "2  18025  5.0 MHz   NaN              NaN     32.20        ---    46.24   dB   \n",
       "3  18025  5.0 MHz  QPSK  25 (RB_Pos:LOW)     32.20        ---    45.69   dB   \n",
       "4  18025  5.0 MHz  QPSK  25 (RB_Pos:LOW)     35.20        ---    49.63   dB   \n",
       "5  18025  5.0 MHz  QPSK  25 (RB_Pos:LOW)     35.20        ---    47.69   dB   \n",
       "6  18025  5.0 MHz  QPSK   8 (RB_Pos:LOW)     29.20        ---    46.10   dB   \n",
       "7  18025  5.0 MHz  QPSK   8 (RB_Pos:LOW)     29.20        ---    51.03   dB   \n",
       "8  18025  5.0 MHz  QPSK   8 (RB_Pos:LOW)     32.20        ---    47.33   dB   \n",
       "9  18025  5.0 MHz  QPSK   8 (RB_Pos:LOW)     32.20        ---    52.07   dB   \n",
       "\n",
       "   Status  \n",
       "0  Passed  \n",
       "1  Passed  \n",
       "2  Passed  \n",
       "3  Passed  \n",
       "4  Passed  \n",
       "5  Passed  \n",
       "6  Passed  \n",
       "7  Passed  \n",
       "8  Passed  \n",
       "9  Passed  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import time\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import os \n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "\n",
    "def read_pdf(file_path):\n",
    "    # Read the PDF file using Camelot\n",
    "    print(f\"Start reading PDF file {file_path}...\")\n",
    "    tables = camelot.read_pdf(file_path, pages='all' )\n",
    "    # clean_tables(tables)\n",
    "    return tables\n",
    "\n",
    "def clean_table(table):\n",
    "    # print(f\"\\nStart cleaning table...\")\n",
    "    # Check if the table has more than 1 column\n",
    "    if table.shape[1] > 1:\n",
    "        # print(f'Table has {table.shape[1]} columns. Cleaning up...')\n",
    "        # # Drop the first column\n",
    "        table = table.drop(columns=0)\n",
    "        # Reset the column names\n",
    "        table.columns = range(table.shape[1])\n",
    "        # print(f'Table now has {table.shape[1]} columns.')\n",
    "    return table\n",
    "\n",
    "def find_table_location(pdf_file, target_table):\n",
    "    print(f\"Searching for table: {target_table}\")\n",
    "    \n",
    "    reader = PdfReader(pdf_file)\n",
    "\n",
    "    pages_with_table = []\n",
    "\n",
    "    for page_num in range(len(reader.pages)):\n",
    "\n",
    "        # Search each page's text for target table\n",
    "        print(f\"Searching page {page_num} out of {len(reader.pages)-1}\")\n",
    "        \n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        # If target table is found, add the page number to the list, start a continuous table\n",
    "        if target_table in text:\n",
    "            print(f\"Start new target table on page {page_num}\")\n",
    "            cont_table = True\n",
    "            pages_with_table.append(page_num)\n",
    "        #elif next page has 6.x.x.x pattern, end of continuous table, add the page number to the list\n",
    "        elif re.search(r'\\d+\\.\\d+\\.\\d+', text):\n",
    "            print(f\"End of continuous table on page {page_num}\")\n",
    "            cont_table = False\n",
    "            pages_with_table.append(page_num)\n",
    "        else:\n",
    "            # print(f\"Continuous table on page {page_num}\")\n",
    "            pass\n",
    "\n",
    "    return pages_with_table\n",
    "\n",
    "\n",
    "def convert_to_ranges(numbers):\n",
    "    \"\"\"\n",
    "    Convert a list of numbers into a list of ranges.\n",
    "    \"\"\"\n",
    "    ranges = []\n",
    "    \n",
    "    for i in range(0, len(numbers), 2):\n",
    "        \n",
    "        if i < len(numbers) - 1:\n",
    "            ranges.append(f\"{numbers[i]}-{numbers[i+1]}\")\n",
    "        else:\n",
    "            ranges.append(str(numbers[i]))\n",
    "\n",
    "    return ranges\n",
    "\n",
    "def display_tables(tables):\n",
    "    # Set the max column width to a high number (e.g., 1000) to display long contents\n",
    "    pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "    # Display all tables\n",
    "    print(f\"Displaying {len(tables)} tables:\")\n",
    "    for i, table in enumerate(tables):\n",
    "        table_number = i + 1\n",
    "        print(f\"\\nTable {table_number}\")\n",
    "        display(table.df)\n",
    "\n",
    "def display_processed_tables(tables):\n",
    "    # Set the max column width to a high number (e.g., 1000) to display long contents\n",
    "    pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "    # Display all processed tables\n",
    "    print(f\"\\nDisplaying {len(tables)} tables:\")\n",
    "    for i, df in enumerate(tables):\n",
    "        print(f\"Table {i + 1}\")\n",
    "        display(df)\n",
    "\n",
    "def find_target_table(tables, desired_name):\n",
    "    \n",
    "    current_table = None\n",
    "    desired_tables = []\n",
    "    \n",
    "    #Run through table_list\n",
    "    for table in tables:\n",
    "        first_cell = table.df.iloc[0,0].split('\\n')[0]\n",
    "        print(f\"\\nChecking table: {first_cell}\")\n",
    "        #If the cell in first row, first column has the desire format \"6.x.x.x\" AND the desire_name: Start a new table\n",
    "        if first_cell.startswith(\"6.\") and desired_name in first_cell:\n",
    "            # Found start of new desired table\n",
    "            print(f\"Found start of new desired table:{first_cell}\") \n",
    "            \n",
    "            if current_table is None:\n",
    "                current_table = table.df.copy()\n",
    "            \n",
    "            # print(f\"Found start of new desired table:\")   \n",
    "            # display(current_table)\n",
    "\n",
    "        \n",
    "        #if the table doesnt match the desire_format AND there is a current_table: concat this table into the current table:         \n",
    "        elif current_table is not None and not table.df.iloc[0][1].startswith(\"6.\") and not table.df.iloc[0][0].startswith(\"6.\") :  \n",
    "            # Continuation of previous desired table\n",
    "            print(f\"Found continuation of previous desired table: {table.df.iloc[0][1]}\")\n",
    "            # print(f\"test: {table.df.iloc[0][1]}\")\n",
    "            # print(f\"Found continuous table, before cleaning:\")   \n",
    "            # display(table.df)\n",
    "            #Clean table before concat:\n",
    "            table.df = clean_table(table.df)\n",
    "            # print(f\"Continuous table after cleaning:\")   \n",
    "            # display(table.df)\n",
    "            current_table = pd.concat([current_table, table.df])\n",
    "\n",
    "            # print(f\"Table after concat:\")\n",
    "            # display(current_table)\n",
    "            \n",
    "        else: \n",
    "            #else: return the current table, and reset the current_table to None\n",
    "            print(f\"Skipping a none-desired table: {first_cell}\")\n",
    "            if current_table is not None:\n",
    "                # Save the current table\n",
    "                desired_tables.append(current_table)\n",
    "                #Reset, mark end of the desired table\n",
    "                current_table = None\n",
    "                       \n",
    "    print(f\"Finished find and concatenate tables: {desired_tables}\")  \n",
    "    return desired_tables\n",
    "\n",
    "def process_tables(tables):  \n",
    "\n",
    "    processed_tables = []\n",
    "    \n",
    "    for i, table in enumerate(tables):\n",
    "        # print(f\"\\nProcessing table {i+1}...\")\n",
    "        # print(f\"Table before processing:\")\n",
    "        # display(table)\n",
    "\n",
    "    \n",
    "        # Split the first cell of the first row and use it as column headers\n",
    "        first_row = table.iloc[0, 0]\n",
    "        headers = first_row.split('\\n')  \n",
    "        # print(f\"First row: {first_row}\")\n",
    "        # print(f\"Headers: {headers}\")\n",
    "        # headers.append(\"MissingHeader\")\n",
    "        table.columns = headers\n",
    "        \n",
    "        # Extract the table name from the first row\n",
    "        table_name = table.iloc[0, 0].split('\\n')[0]\n",
    "\n",
    "        \n",
    "        # Extract Band info from column 2\n",
    "        # print(f\"Extracting Band info...\")\n",
    "        line2 = table.iloc[1,0]\n",
    "        # print(f\"line2: {line2}\")\n",
    "        if 'Band' in line2:\n",
    "            band_info = line2.split(' ')\n",
    "            for word in band_info:\n",
    "                if word.startswith('Band'):\n",
    "                    band_num = word[4:]  # Extract everything after \"Band\"\n",
    "                    table.insert(1, 'Band', band_num)\n",
    "                    break\n",
    "            else:\n",
    "                print(f\"No 'Band' keyword in line: {line2}\")\n",
    "         \n",
    "\n",
    "        # print(\"Table after header:\")\n",
    "        # display(table)\n",
    "          \n",
    "        # # Check if the expected columns are in the table\n",
    "        # if 'Unit' not in table.columns:\n",
    "        #     print(f\"Table {i+1} doesn't have the expected structure. Skipping...\")\n",
    "        #     continue\n",
    "  \n",
    "        # Extract Testname, ULCH, BW, MOD, RD info\n",
    "        # print(f\"Extracting Testname, ULCH, BW, MOD, RD info...\")\n",
    "        # Define patterns\n",
    "        testname_pattern = r\"(.*):@\"\n",
    "        ulch_pattern = r\"ULCH: (\\d+),\"\n",
    "        bw_pattern = r\"BW: ([\\d\\.]+ MHz)\"\n",
    "        mod_pattern = r\"UL_MOD_RB: ([^,]+),\"\n",
    "        rd_pattern = r\"UL_MOD_RB: [^,]+, (.*)\"\n",
    "\n",
    "        # Extract info\n",
    "        table['Testname'] = table.iloc[:,0].str.extract(testname_pattern)\n",
    "        table['ULCH'] = table.iloc[:,0].str.extract(ulch_pattern)\n",
    "        table['BW'] = table.iloc[:,0].str.extract(bw_pattern)\n",
    "        table['MOD'] = table.iloc[:,0].str.extract(mod_pattern)\n",
    "        table['RD'] = table.iloc[:,0].str.extract(rd_pattern)\n",
    "        \n",
    "        # print(f\"Table before split Unit column:\")\n",
    "        # display(table)\n",
    "   \n",
    "        # Split 'Measured' and 'Unit' columns \n",
    "        # Create a temporary DataFrame for the split results\n",
    "        split_df = table['Unit'].str.split(expand=True)\n",
    "\n",
    "        # Assign the split results to 'Measured' and 'Unit' only where there are values\n",
    "        table.loc[split_df[0].notna(), 'Measured'] = split_df.loc[split_df[0].notna(), 0]\n",
    "        table.loc[split_df[1].notna(), 'Unit'] = split_df.loc[split_df[1].notna(), 1]\n",
    "\n",
    "        # Drop the first column\n",
    "        table.drop(table.columns[0], axis=1, inplace=True)\n",
    "\n",
    "        # Create a new column filled with the table name\n",
    "        table.insert(0, 'Table Name', table_name)\n",
    "        table = table.iloc[1:]\n",
    "        \n",
    "        # Reorganize the columns\n",
    "        # print(f\"Reorganizing columns...\")\n",
    "        new_column_order = ['Table Name', 'Testname', 'Band', 'ULCH', 'BW', 'MOD', 'RD', 'Limit Low', 'Limit High', 'Measured', 'Unit', 'Status']\n",
    "        table = table.reindex(columns=new_column_order)\n",
    "\n",
    "        # Drop rows with NaN values in Testname and Band columns\n",
    "        table = table.dropna(subset=['Testname'], how='all')\n",
    "\n",
    "\n",
    "        # Reset the index\n",
    "        table.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        #Append processed table to processed_tables:\n",
    "        processed_tables.append(table)\n",
    "        \n",
    "        \n",
    "    return processed_tables\n",
    "\n",
    "\n",
    "#UI TKINTER:\n",
    "\n",
    "# # Add a GUI file picker\n",
    "# root = tk.Tk()\n",
    "# root.withdraw()\n",
    "# file_path = filedialog.askopenfilename()\n",
    "# pdf_file = file_path\n",
    "\n",
    "target_table = \"6.6.2.3 Adjacent Channel Leakage Power Ratio\" \n",
    "pdf_file = \"30pages_6.6.2.3_Adjacent_Channel.pdf\"\n",
    "\n",
    "\n",
    "# Extract name without extension\n",
    "file_name = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "\n",
    "# \"LTE_3GPP_v15_r8_FDD_FORD_All_TEMPS_TCU2_5_ROW_012023_5GSIM_AT_2023-06-28_16-27-57_188.pdf\"\n",
    "#  \"25C_DATA_Extract(1temperatureOnly).pdf\"\n",
    "# \"300_pages_extract.pdf\"\n",
    "\n",
    "\n",
    "target_table = \"6.6.2.3 Adjacent Channel Leakage Power Ratio\" \n",
    "# target_table = \"6.2.2 Maximum Output Power\" \n",
    "# pdf_file = \"300_pages_extract.pdf\"\n",
    "# Extract name without extension\n",
    "file_name = os.path.splitext(os.path.basename(pdf_file))[0]\n",
    "\n",
    "\n",
    "# Find target table pages\n",
    "pages = find_table_location(pdf_file, target_table)\n",
    "\n",
    "# Format page numbers for camelot\n",
    "page_ranges = convert_to_ranges(pages)\n",
    "print(f\"Pages to read: {page_ranges}\")\n",
    "\n",
    "\n",
    "clean_tables = []\n",
    "total_ranges = len(page_ranges)\n",
    "\n",
    "def find_target_table(tables, desired_name):\n",
    "    \n",
    "    current_table = None\n",
    "    desired_tables = []\n",
    "    \n",
    "    #Run through table_list\n",
    "    for table in tables:\n",
    "        first_cell = table.df.iloc[0,0].split('\\n')[0]\n",
    "        print(f\"\\nChecking table: {first_cell}\")\n",
    "        #If the cell in first row, first column has the desire format \"6.x.x.x\" AND the desire_name: Start a new table\n",
    "        if first_cell.startswith(\"6.\") and desired_name in first_cell:\n",
    "            # Found start of new desired table\n",
    "            print(f\"Found start of new desired table:{first_cell}\") \n",
    "            \n",
    "            if current_table is None:\n",
    "                current_table = table.df.copy()\n",
    "            \n",
    "            # print(f\"Found start of new desired table:\")   \n",
    "            # display(current_table)\n",
    "\n",
    "        \n",
    "        #if the table doesnt match the desire_format AND there is a current_table: concat this table into the current table:         \n",
    "        elif current_table is not None and not table.df.iloc[0][1].startswith(\"6.\") and not table.df.iloc[0][0].startswith(\"6.\") :  \n",
    "            # Continuation of previous desired table\n",
    "            print(f\"Found continuation of previous desired table: {table.df.iloc[0][1]}\")\n",
    "            # print(f\"test: {table.df.iloc[0][1]}\")\n",
    "            # print(f\"Found continuous table, before cleaning:\")   \n",
    "            # display(table.df)\n",
    "            #Clean table before concat:\n",
    "            table.df = clean_table(table.df)\n",
    "            # print(f\"Continuous table after cleaning:\")   \n",
    "            # display(table.df)\n",
    "            current_table = pd.concat([current_table, table.df])\n",
    "\n",
    "            # print(f\"Table after concat:\")\n",
    "            # display(current_table)\n",
    "            \n",
    "        else: \n",
    "            #else: return the current table, and reset the current_table to None\n",
    "            print(f\"Skipping a none-desired table: {first_cell}\")\n",
    "            if current_table is not None:\n",
    "                # Save the current table\n",
    "                print(f\"Saving table: {current_table}\")\n",
    "                desired_tables.append(current_table)\n",
    "                #Reset, mark end of the desired table\n",
    "                current_table = None\n",
    "                       \n",
    "    # Check if the last table in the list was a continuation of a desired table\n",
    "    if current_table is not None:\n",
    "        print(f\"Saving table: {current_table}\")\n",
    "        desired_tables.append(current_table)\n",
    "        \n",
    "    return desired_tables\n",
    "\n",
    "for i, page_range in enumerate(page_ranges):\n",
    "    \n",
    "    print(f\"\\nProcessing {i+1}/{total_ranges}: {page_range}\")\n",
    "    # Calculate the estimate time remaining based on the progress so far\n",
    "    progress = i / total_ranges\n",
    "    time_remaining = (total_ranges - i) * 9 / 60\n",
    "    print(f\"Estimated time remaining: {time_remaining:.2f} minutes\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    # Read all tables from pdf\n",
    "    long_tables = camelot.read_pdf(pdf_file, pages=page_range, backend=\"poppler\")\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to load table: {end_time - start_time:.2f} seconds\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    desire_tables = find_target_table(long_tables, target_table)\n",
    "    display_processed_tables(desire_tables)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to find target table: {end_time - start_time:.2f} seconds\")\n",
    "   \n",
    "    \n",
    "    start_time = time.time()\n",
    "    processed_table = process_tables(desire_tables)\n",
    "    end_time = time.time()\n",
    "    print(f\"Time taken to process tables: {end_time - start_time:.2f} seconds\")\n",
    "    # display_processed_tables(processed_table)\n",
    "    \n",
    "    \n",
    "    #append to clean_tables:\n",
    "    clean_tables.extend(processed_table)\n",
    "\n",
    "\n",
    "# Concatenate all the dataframes in the list into a single dataframe\n",
    "if not clean_tables:\n",
    "    print(\"No tables extracted\")\n",
    "else: \n",
    "    all_tables = pd.concat(clean_tables, ignore_index=True)\n",
    "    display(all_tables.head(10)) # Display the first few rows of the resulting dataframe\n",
    "    # Save to Excel using file name\n",
    "    excel_file = f\"final_{file_name}.xlsx\" \n",
    "    all_tables.to_excel(excel_file, index=False)\n",
    "\n",
    "    #Auto open folder:\n",
    "    import subprocess\n",
    "    import platform\n",
    "    folder_path = os.path.dirname(excel_file)\n",
    "\n",
    "    if platform.system() == 'Windows':\n",
    "        os.startfile(folder_path)\n",
    "\n",
    "    elif platform.system() == 'Darwin': \n",
    "        subprocess.Popen(['open', folder_path])\n",
    "\n",
    "    else:\n",
    "        subprocess.Popen(['xdg-open', folder_path])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import time\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import os \n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "import re\n",
    "\n",
    "def find_table_location(pdf_file, target_table):\n",
    "    print(f\"Searching for table: {target_table}\")\n",
    "    \n",
    "    reader = PdfReader(pdf_file)\n",
    "\n",
    "    pages_with_table = []\n",
    "\n",
    "    for page_num in range(len(reader.pages)):\n",
    "\n",
    "        # Search each page's text for target table\n",
    "        print(f\"Searching page {page_num} out of {len(reader.pages)-1}\")\n",
    "        \n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        if target_table in text:\n",
    "            print(f\"Found table on page {page_num}\")\n",
    "            pages_with_table.append(page_num)\n",
    "\n",
    "            # Loop through next pages until the end of the continuous table is reached\n",
    "            next_page_num = page_num + 1\n",
    "            # print(f\"Next page number: {next_page_num}\")\n",
    "            while next_page_num < len(reader.pages):\n",
    "                next_page = reader.pages[next_page_num]\n",
    "                next_text = next_page.extract_text()\n",
    "\n",
    "                # Check if next page contains the table pattern\n",
    "                if not re.search(r'6\\.\\d+\\.\\d+(\\.\\d+)?', next_text):\n",
    "                    pages_with_table.append(next_page_num)\n",
    "                    print(f\"Found continuation of table on page {next_page_num}\")\n",
    "                    next_page_num += 1\n",
    "                else:\n",
    "                    # End of continuous table\n",
    "                    print(f\"End of continuous table on page {next_page_num}\")\n",
    "                    pages_with_table.append(next_page_num)\n",
    "                    break\n",
    "        page_num = next_page_num\n",
    "\n",
    "    return pages_with_table\n",
    "\n",
    "target_table = \"6.6.2.3 Adjacent Channel Leakage Power Ratio\" \n",
    "pdf_file = \"30pages_6.6.2.3_Adjacent_Channel.pdf\"\n",
    "pages = find_table_location(pdf_file, target_table)\n",
    "print(pages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working new find table location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for table: 6.6.2.3 Adjacent Channel Leakage Power Ratio\n",
      "Searching page 0 out of 19\n",
      "Searching page 1 out of 19\n",
      "Searching page 2 out of 19\n",
      "Start new target table on page 2\n",
      "Searching page 3 out of 19\n",
      "Searching page 4 out of 19\n",
      "Searching page 5 out of 19\n",
      "Searching page 6 out of 19\n",
      "Searching page 7 out of 19\n",
      "Searching page 8 out of 19\n",
      "Searching page 9 out of 19\n",
      "Searching page 10 out of 19\n",
      "Searching page 11 out of 19\n",
      "Searching page 12 out of 19\n",
      "Searching page 13 out of 19\n",
      "Searching page 14 out of 19\n",
      "Searching page 15 out of 19\n",
      "Searching page 16 out of 19\n",
      "Searching page 17 out of 19\n",
      "Searching page 18 out of 19\n",
      "Searching page 19 out of 19\n",
      "End of continuous table on page 19\n",
      "[2, 19]\n"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import time\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "import os \n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "\n",
    "import re\n",
    "\n",
    "def find_table_location(pdf_file, target_table):\n",
    "    print(f\"Searching for table: {target_table}\")\n",
    "    \n",
    "    reader = PdfReader(pdf_file)\n",
    "\n",
    "    pages_with_table = []\n",
    "\n",
    "    for page_num in range(len(reader.pages)):\n",
    "\n",
    "        # Search each page's text for target table\n",
    "        print(f\"Searching page {page_num} out of {len(reader.pages)-1}\")\n",
    "        \n",
    "        page = reader.pages[page_num]\n",
    "        text = page.extract_text()\n",
    "        \n",
    "        # If target table is found, add the page number to the list, start a continuous table\n",
    "        if target_table in text:\n",
    "            print(f\"Start new target table on page {page_num}\")\n",
    "            cont_table = True\n",
    "            pages_with_table.append(page_num)\n",
    "        #elif next page has 6.x.x.x pattern, end of continuous table, add the page number to the list\n",
    "        elif re.search(r'\\d+\\.\\d+\\.\\d+', text):\n",
    "            print(f\"End of continuous table on page {page_num}\")\n",
    "            cont_table = False\n",
    "            pages_with_table.append(page_num)\n",
    "        else:\n",
    "            # print(f\"Continuous table on page {page_num}\")\n",
    "            pass\n",
    "\n",
    "    return pages_with_table\n",
    "\n",
    "target_table = \"6.6.2.3 Adjacent Channel Leakage Power Ratio\" \n",
    "pdf_file = \"30pages_6.6.2.3_Adjacent_Channel.pdf\"\n",
    "pages = find_table_location(pdf_file, target_table)\n",
    "print(pages)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paul",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
